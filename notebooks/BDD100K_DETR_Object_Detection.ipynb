{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DETR-based Object Detection on BDD100K\n",
        "\n",
        "This notebook demonstrates an end-to-end object detection pipeline using\n",
        "DETR (DEtection TRansformer) on a sample of the BDD100K dataset.\n",
        "\n",
        "The notebook is fully reproducible on Google Colab and includes:\n",
        "- Dataset extraction\n",
        "- Model training (sanity check)\n",
        "- Inference and visualization\n",
        "\n",
        "Dataset is loaded via Google Drive to avoid large downloads.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62ieR0-2OW2v"
      },
      "source": [
        "### 1. Mount Google Drive\n",
        "\n",
        "This cell mounts Google Drive inside Google Colab so that the dataset ZIP file\n",
        "stored in Drive can be accessed programmatically. This avoids manual dataset\n",
        "downloads and ensures reproducibility for reviewers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Afp30HVWTxCZ",
        "outputId": "5d6555a5-e625-41ad-e24e-ad6c04e2134e"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.13.9)' requires the ipykernel package.\n",
            "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'e:/dert_bdd100k/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_lStLNIOb-1"
      },
      "source": [
        "### 2. Extract BDD100K Sample Dataset\n",
        "\n",
        "In this step, a compressed sample of the BDD100K dataset is extracted from\n",
        "Google Drive into the Colab filesystem. The extracted folder contains train,\n",
        "validation, and test splits along with COCO-format annotation files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TetAWk7qT7mO",
        "outputId": "43c4cc09-27e0-4628-994e-ef563ea9072b"
      },
      "outputs": [],
      "source": [
        "import os, zipfile\n",
        "\n",
        "ZIP_PATH = \"/content/drive/MyDrive/BBD_project/100k_sample.zip\"\n",
        "OUT_DIR  = \"/content/100k_sample\"\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(ZIP_PATH, 'r') as z:\n",
        "    z.extractall(OUT_DIR)S\n",
        "\n",
        "print(\"Extracted to:\", OUT_DIR)\n",
        "print(\"Top-level:\", os.listdir(OUT_DIR))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDZNeHn2Of91"
      },
      "source": [
        "### 3. Verify Dataset and Annotation Files\n",
        "\n",
        "This cell verifies the presence of dataset folders and COCO annotation files.\n",
        "It also prints dataset statistics such as number of images, annotations, and\n",
        "object categories to ensure data integrity before training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDSAF_puUUkM",
        "outputId": "a78382d1-8f05-4fb7-9fda-85e1d716f87a"
      },
      "outputs": [],
      "source": [
        "import os, json\n",
        "\n",
        "DATA_DIR = \"/content/100k_sample/100k_sample\"\n",
        "\n",
        "print(\"Folders:\", os.listdir(DATA_DIR))\n",
        "\n",
        "for f in [\"train_coco.json\", \"val_coco.json\", \"test_coco.json\"]:\n",
        "    p = os.path.join(DATA_DIR, f)\n",
        "    print(f, \"exists:\", os.path.exists(p), \"size:\", os.path.getsize(p) if os.path.exists(p) else None)\n",
        "\n",
        "train = json.load(open(os.path.join(DATA_DIR, \"train_coco.json\"), \"r\"))\n",
        "print(\"num_images:\", len(train[\"images\"]))\n",
        "print(\"num_annotations:\", len(train[\"annotations\"]))\n",
        "print(\"categories:\", [c[\"name\"] for c in train[\"categories\"]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my5T7KyUOkBV"
      },
      "source": [
        "### 4. Install Required Libraries\n",
        "\n",
        "All required deep learning and computer vision libraries are installed here,\n",
        "including PyTorch, TorchVision, Transformers (DETR), and pycocotools.\n",
        "This ensures the notebook runs independently on any Colab environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qupP6EnWV3Es",
        "outputId": "22845553-a3b4-4ee7-f6f3-439148b51b95"
      },
      "outputs": [],
      "source": [
        "!pip -q install transformers==4.43.3 accelerate pycocotools\n",
        "!pip -q install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jGA0-vwOqOh"
      },
      "source": [
        "### Cell 5: Model Initialization and Sanity Training\n",
        "\n",
        "This cell initializes the DETR object detection model with a ResNet-50 backbone\n",
        "and performs a short sanity training run on the BDD100K sample dataset.\n",
        "The purpose is to verify correct data loading, loss computation, and backpropagation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fYmBCmiFWQ8z",
        "outputId": "bb635778-958c-427e-ba2d-1014e8c7e85d"
      },
      "outputs": [],
      "source": [
        "import os, torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pycocotools.coco import COCO\n",
        "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
        "\n",
        "DATA_DIR = \"/content/100k_sample/100k_sample\"  # change if needed\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_ann = os.path.join(DATA_DIR, \"train_coco.json\")\n",
        "val_ann   = os.path.join(DATA_DIR, \"val_coco.json\")\n",
        "\n",
        "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
        "\n",
        "class CocoDetrDataset(Dataset):\n",
        "    def __init__(self, img_dir, ann_file):\n",
        "        self.img_dir = img_dir\n",
        "        self.coco = COCO(ann_file)\n",
        "        self.ids = list(self.coco.imgs.keys())\n",
        "\n",
        "        self.cat_ids = sorted(self.coco.getCatIds())\n",
        "        self.cat2idx = {cid: i for i, cid in enumerate(self.cat_ids)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.ids[idx]\n",
        "        img_info = self.coco.loadImgs(img_id)[0]\n",
        "        path = os.path.join(self.img_dir, img_info[\"file_name\"])\n",
        "        image = Image.open(path).convert(\"RGB\")\n",
        "\n",
        "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
        "        anns = self.coco.loadAnns(ann_ids)\n",
        "\n",
        "        clean_anns = []\n",
        "        for a in anns:\n",
        "            x, y, w, h = a[\"bbox\"]\n",
        "            if w <= 1 or h <= 1:\n",
        "                continue\n",
        "            clean_anns.append({\n",
        "                \"bbox\": [float(x), float(y), float(w), float(h)],\n",
        "                \"category_id\": int(self.cat2idx[a[\"category_id\"]]),\n",
        "                \"area\": float(a.get(\"area\", w*h)),\n",
        "                \"iscrowd\": int(a.get(\"iscrowd\", 0)),\n",
        "            })\n",
        "\n",
        "        target = {\"image_id\": int(img_id), \"annotations\": clean_anns}\n",
        "        return image, target\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images, targets = zip(*batch)\n",
        "    return processor(images=list(images), annotations=list(targets), return_tensors=\"pt\")\n",
        "\n",
        "def to_device(x, device):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return x.to(device)\n",
        "    if isinstance(x, dict):\n",
        "        return {k: to_device(v, device) for k, v in x.items()}\n",
        "    if isinstance(x, list):\n",
        "        return [to_device(v, device) for v in x]\n",
        "    return x\n",
        "\n",
        "train_ds = CocoDetrDataset(os.path.join(DATA_DIR, \"train\"), train_ann)\n",
        "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, collate_fn=collate_fn, num_workers=0)\n",
        "\n",
        "num_classes = len(train_ds.cat_ids)\n",
        "\n",
        "model = DetrForObjectDetection.from_pretrained(\n",
        "    \"facebook/detr-resnet-50\",\n",
        "    num_labels=num_classes,\n",
        "    ignore_mismatched_sizes=True\n",
        ").to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "model.train()\n",
        "steps = 0\n",
        "\n",
        "for batch in train_loader:\n",
        "    batch = dict(batch)\n",
        "\n",
        "    batch[\"pixel_values\"] = batch[\"pixel_values\"].to(DEVICE)\n",
        "    if \"pixel_mask\" in batch:\n",
        "        batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(DEVICE)\n",
        "\n",
        "    # move nested label tensors to GPU\n",
        "    new_labels = []\n",
        "    for t in batch[\"labels\"]:\n",
        "        t = dict(t)\n",
        "        for k, v in t.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                t[k] = v.to(DEVICE)\n",
        "        new_labels.append(t)\n",
        "    batch[\"labels\"] = new_labels\n",
        "\n",
        "    out = model(**batch)\n",
        "    loss = out.loss\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    steps += 1\n",
        "    if steps % 20 == 0:\n",
        "        print(\"step:\", steps, \"loss:\", float(loss))\n",
        "\n",
        "    if steps >= 100:\n",
        "        break\n",
        "\n",
        "print(\"Sanity training done. CUDA:\", torch.cuda.is_available(), \"num_classes:\", num_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQhtJI-6Ovxo"
      },
      "source": [
        "### Cell 6: Inference and Result Visualization\n",
        "\n",
        "This cell performs inference on a randomly selected validation image and\n",
        "visualizes the predicted bounding boxes along with class labels and confidence\n",
        "scores. This demonstrates the end-to-end functionality of the trained model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "KX4rjK0ZXJZ1",
        "outputId": "13db9635-3ce5-4fe1-f39a-3e25fded347a"
      },
      "outputs": [],
      "source": [
        "import random, torch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# pick one random val image\n",
        "img_id = random.choice(val_ds.ids)\n",
        "img_info = val_ds.coco.loadImgs(img_id)[0]\n",
        "img_path = os.path.join(DATA_DIR, \"val\", img_info[\"file_name\"])\n",
        "image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "# prepare inputs\n",
        "inputs = processor(images=image, return_tensors=\"pt\")\n",
        "inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# post-process predictions\n",
        "target_sizes = torch.tensor([image.size[::-1]]).to(DEVICE)  # (h, w)\n",
        "results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.20)[0]\n",
        "\n",
        "# label names (from your COCO categories, in same 0..K-1 order)\n",
        "label_names = [val_ds.coco.cats[cid][\"name\"] for cid in sorted(val_ds.coco.getCatIds())]\n",
        "\n",
        "# draw\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(image)\n",
        "ax = plt.gca()\n",
        "\n",
        "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
        "    x1, y1, x2, y2 = box.tolist()\n",
        "    rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor=\"red\", facecolor=\"none\")\n",
        "    ax.add_patch(rect)\n",
        "    ax.text(x1, y1, f\"{label_names[label]} {score:.2f}\", color=\"white\",\n",
        "            bbox=dict(facecolor=\"red\", alpha=0.6, pad=2))\n",
        "\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Predicted boxes:\", len(results[\"boxes\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59x_I8saPKMS"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXZ5izwNPJzc"
      },
      "source": [
        "### 7. Summary\n",
        "\n",
        "This notebook demonstrates an end-to-end pipeline for object detection on the\n",
        "BDD100K dataset using DETR. It includes dataset preparation, model training,\n",
        "and inference visualization. All steps are fully reproducible using Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlpjB4fEYBdx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
